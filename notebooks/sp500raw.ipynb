{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import time\n",
    "from pytz import timezone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee7edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) —— Data Import & Preprocessing —— #\n",
    "\n",
    "DATA_DIR = \"../SPX\"\n",
    "OUTPUT_FEATURE_CSV = \"../csvfiles_python/features_360_raw.csv\"\n",
    "OUTPUT_ALLSET_CSV  = \"../csvfiles_python/allSet_360_raw.csv\"\n",
    "\n",
    "def load_data(path):\n",
    "    files = glob.glob(os.path.join(path, \"*.txt\"))\n",
    "    dfs = []\n",
    "    for f in sorted(files):\n",
    "        df = pd.read_csv(f, names=[\"DateTime\",\"Open\",\"High\",\"Low\",\"Close\"],\n",
    "                         sep=\",\", parse_dates=[\"DateTime\"])\n",
    "        dfs.append(df)\n",
    "    spx = pd.concat(dfs, ignore_index=True)\n",
    "    # localize to EST\n",
    "    spx[\"DateTime\"] = spx[\"DateTime\"].dt.tz_localize(timezone(\"US/Eastern\"))\n",
    "    spx.set_index(\"DateTime\", inplace=True)\n",
    "    # filter trading hours 9:30–16:00\n",
    "    return spx.between_time(\"09:30\",\"16:00\")\n",
    "\n",
    "spx = load_data(DATA_DIR)\n",
    "\n",
    "# Drop duplicates\n",
    "spx = spx[~spx.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bedfa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) —— Create daily labels —— #\n",
    "\n",
    "# group by calendar date\n",
    "spx[\"Date\"] = spx.index.date\n",
    "groups = spx.groupby(\"Date\")\n",
    "\n",
    "# last-minute close price per day\n",
    "lmP = groups[\"Close\"].last()\n",
    "\n",
    "# average price from start to (end − 30 mins)\n",
    "avgP = groups.apply(lambda df: df[\"Close\"].iloc[:-30].mean())\n",
    "\n",
    "# binary label: 1 if avgP < lmP else 0\n",
    "y = (avgP < lmP).astype(int)\n",
    "y.name = \"Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25aa98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) —— Technical‐Indicator Functions —— #\n",
    "\n",
    "# Basic EMAs & SMAs\n",
    "def SMA(x, n):\n",
    "    return x.rolling(n, min_periods=n).mean()\n",
    "\n",
    "def EMA(x, n):\n",
    "    return x.ewm(span=n, adjust=False).mean()\n",
    "\n",
    "def DEMA(x, n):\n",
    "    e = EMA(x, n)\n",
    "    return 2*e - EMA(e, n)\n",
    "\n",
    "# True Range & ATR\n",
    "def ATR(H, L, C, n=14):\n",
    "    prevC = C.shift(1)\n",
    "    tr = pd.concat([\n",
    "        H - L,\n",
    "        (H - prevC).abs(),\n",
    "        (L - prevC).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "    return EMA(tr, n)\n",
    "\n",
    "# Average Directional Index (ADX)\n",
    "def ADX(H, L, C, n=14):\n",
    "    up = H.diff()\n",
    "    down = -L.diff()\n",
    "    plusDM  = np.where((up>down)&(up>0), up, 0.0)\n",
    "    minusDM = np.where((down>up)&(down>0), down, 0.0)\n",
    "    tr = pd.concat([\n",
    "        H-L,\n",
    "        (H - C.shift(1)).abs(),\n",
    "        (L - C.shift(1)).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "    atr = EMA(tr, n)\n",
    "    plusDI  = 100 * EMA(pd.Series(plusDM, index=H.index), n) / atr\n",
    "    minusDI = 100 * EMA(pd.Series(minusDM, index=H.index), n) / atr\n",
    "    dx = 100 * ( (plusDI - minusDI).abs() / (plusDI + minusDI) )\n",
    "    return EMA(dx, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e23f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aroon\n",
    "def aroon(xH, xL, n=14):\n",
    "    def _aroon_up(series):\n",
    "        idx = series.argmax()\n",
    "        return ((n - (len(series)-1 - idx)) / n) * 100\n",
    "    def _aroon_dn(series):\n",
    "        idx = series.argmin()\n",
    "        return ((n - (len(series)-1 - idx)) / n) * 100\n",
    "\n",
    "    au = xH.rolling(n).apply(_aroon_up, raw=True)\n",
    "    ad = xL.rolling(n).apply(_aroon_dn, raw=True)\n",
    "    return pd.DataFrame({\"aroonUp\": au, \"aroonDn\": ad})\n",
    "\n",
    "# Bollinger Bands\n",
    "def BBands(x, n=20, k=2):\n",
    "    m = SMA(x, n)\n",
    "    sd = x.rolling(n).std()\n",
    "    return pd.DataFrame({\n",
    "        \"bb_up\":   m + k*sd,\n",
    "        \"bb_mid\":  m,\n",
    "        \"bb_low\":  m - k*sd\n",
    "    })\n",
    "\n",
    "# Commodity Channel Index\n",
    "def CCI(H, L, C, n=20):\n",
    "    TP = (H + L + C) / 3\n",
    "    M  = SMA(TP, n)\n",
    "    MD = TP.rolling(n).apply(lambda s: np.mean(np.abs(s - s.mean())), raw=True)\n",
    "    return (TP - M) / (0.015 * MD)\n",
    "\n",
    "# Chaikin Volatility\n",
    "def chaikin_volatility(H, L, n=10, ema_n=10):\n",
    "    hl = H - L\n",
    "    e1 = EMA(hl, ema_n)\n",
    "    e2 = e1.shift(n)\n",
    "    return (e1 - e2) / e2 * 100\n",
    "\n",
    "# Close Location Value\n",
    "def CLV(H, L, C):\n",
    "    return ((C - L) - (H - C)) / (H - L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e4969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chande Momentum Oscillator\n",
    "def CMO(x, n=14):\n",
    "    diff = x.diff()\n",
    "    up = diff.where(diff>0, 0.0).rolling(n).sum()\n",
    "    dn = (-diff).where(diff<0, 0.0).rolling(n).sum()\n",
    "    return 100 * (up - dn) / (up + dn)\n",
    "\n",
    "# Centre of Gravity Indicator (CTI)\n",
    "#  TTR’s CTI uses n=10 by default: CTI = (C - SMA(C,n)) / SMA(abs(C - SMA(C,n)),n)\n",
    "def CTI(C, n=10):\n",
    "    m = SMA(C, n)\n",
    "    dev = (C - m).abs()\n",
    "    return (C - m) / SMA(dev, n)\n",
    "\n",
    "# Donchian Channel\n",
    "def DonchianChannel(H, L, n=20):\n",
    "    up = H.rolling(n).max()\n",
    "    dn = L.rolling(n).min()\n",
    "    mid = (up + dn) / 2\n",
    "    return pd.DataFrame({\"dc_up\": up, \"dc_mid\": mid, \"dc_dn\": dn})\n",
    "\n",
    "# Detrended Price Oscillator\n",
    "def DPO(x, n=20):\n",
    "    m = SMA(x, n)\n",
    "    shift = int(n/2 + 1)\n",
    "    return x.shift(shift) - m\n",
    "\n",
    "# Directional Volatility Index (DVI)\n",
    "#  TTR’s DVI default n=14: DVI = ROC of range\n",
    "def DVI(C, n=14):\n",
    "    rng = C.diff().abs()\n",
    "    prev = rng.shift(n)\n",
    "\n",
    "    # safe division: if prev==0 → NaN, else compute as usual\n",
    "    dvi = (rng - prev) / prev * 100\n",
    "    dvi = dvi.where(prev != 0)   # sets those inf entries to NaN\n",
    "\n",
    "    return dvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guppy Multiple Moving Average\n",
    "def GMMA(x):\n",
    "    short = [3,5,8,10,12,15]\n",
    "    long  = [30,35,40,45,50,60]\n",
    "    df = {}\n",
    "    for i in short: df[f\"gmma_s{i}\"] = EMA(x, i)\n",
    "    for i in long:  df[f\"gmma_l{i}\"] = EMA(x, i)\n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "# Know Sure Thing\n",
    "def KST(C, r1=10, r2=15, r3=20, r4=30, \n",
    "        n1=10, n2=10, n3=10, n4=15):\n",
    "    roc1 = C.diff(r1)/C.shift(r1)\n",
    "    roc2 = C.diff(r2)/C.shift(r2)\n",
    "    roc3 = C.diff(r3)/C.shift(r3)\n",
    "    roc4 = C.diff(r4)/C.shift(r4)\n",
    "    kst = (SMA(roc1, n1)*1 +\n",
    "           SMA(roc2, n2)*2 +\n",
    "           SMA(roc3, n3)*3 +\n",
    "           SMA(roc4, n4)*4)\n",
    "    signal = SMA(kst, 9)\n",
    "    return pd.DataFrame({\"kst\": kst, \"signal\": signal})\n",
    "\n",
    "# Lagged differences\n",
    "def lags(H, L, C, n=1):\n",
    "    # show lagged close differences by default\n",
    "    return C.diff(n)\n",
    "\n",
    "# MACD\n",
    "def MACD(C, n_fast=12, n_slow=26, n_sig=9):\n",
    "    fast = EMA(C, n_fast)\n",
    "    slow = EMA(C, n_slow)\n",
    "    macd = fast - slow\n",
    "    sig  = EMA(macd, n_sig)\n",
    "    hist = macd - sig\n",
    "    return pd.DataFrame({\"macd\": macd, \"signal\": sig, \"hist\": hist})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c66af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Bands (percent)\n",
    "def PBands(C, n=20, pct=0.025):\n",
    "    m = SMA(C, n)\n",
    "    return pd.DataFrame({\n",
    "        \"pb_up\": m*(1+pct),\n",
    "        \"pb_mid\": m,\n",
    "        \"pb_dn\": m*(1-pct)\n",
    "    })\n",
    "\n",
    "# Rate of Change\n",
    "def ROC(C, n=1):\n",
    "    return (C - C.shift(n)) / C.shift(n) * 100\n",
    "\n",
    "# Momentum\n",
    "def momentum(C, n=1):\n",
    "    return C - C.shift(n)\n",
    "\n",
    "# Relative Strength Index\n",
    "def RSI(C, n=14):\n",
    "    diff = C.diff()\n",
    "    up = diff.where(diff>0, 0.0)\n",
    "    dn = -diff.where(diff<0, 0.0)\n",
    "    ma_up = EMA(up, n)\n",
    "    ma_dn = EMA(dn, n)\n",
    "    rs = ma_up / ma_dn\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "# Running stats\n",
    "def runSum(C, n=10):    return C.rolling(n).sum()\n",
    "def runMin(C, n=10):    return C.rolling(n).min()\n",
    "def runMax(C, n=10):    return C.rolling(n).max()\n",
    "def runMedian(C,n=10):  return C.rolling(n).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e4bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parabolic SAR\n",
    "def SAR(H, L, af0=0.02, af_step=0.02, af_max=0.2):\n",
    "    up = True\n",
    "    af = af0\n",
    "    ep = H[0]\n",
    "    sar = [L.iloc[0]]\n",
    "    for i in range(1, len(H)):\n",
    "        prev_sar = sar[-1]\n",
    "        if up:\n",
    "            new_sar = prev_sar + af*(ep - prev_sar)\n",
    "            new_sar = min(new_sar, L.iloc[i-1], L.iloc[i])\n",
    "            if H.iloc[i] > ep:\n",
    "                ep = H.iloc[i]; af = min(af+af_step, af_max)\n",
    "            if L.iloc[i] < new_sar:\n",
    "                up = False; sar.append(ep); ep = L.iloc[i]; af = af0\n",
    "            else:\n",
    "                sar.append(new_sar)\n",
    "        else:\n",
    "            new_sar = prev_sar + af*(ep - prev_sar)\n",
    "            new_sar = max(new_sar, H.iloc[i-1], H.iloc[i])\n",
    "            if L.iloc[i] < ep:\n",
    "                ep = L.iloc[i]; af = min(af+af_step, af_max)\n",
    "            if H.iloc[i] > new_sar:\n",
    "                up = True; sar.append(ep); ep = H.iloc[i]; af = af0\n",
    "            else:\n",
    "                sar.append(new_sar)\n",
    "    return pd.Series(sar, index=H.index)\n",
    "\n",
    "# Volatility (rolling stdev of log‐returns)\n",
    "def volatility(H, L, C, n=10):\n",
    "    lr = np.log(C / C.shift(1))\n",
    "    return lr.rolling(n).std() * np.sqrt(252* (390/ (16*60)))  # annualize on minute data\n",
    "\n",
    "# Ultimate Oscillator\n",
    "def ultimate_oscillator(H, L, C, s1=7, s2=14, s3=28, w1=4, w2=2, w3=1):\n",
    "    bp = C - np.minimum(L, C.shift(1))\n",
    "    tr = np.maximum(H - L, np.maximum((H-C.shift(1)).abs(), (L-C.shift(1)).abs()))\n",
    "    avg1 = bp.rolling(s1).sum() / tr.rolling(s1).sum()\n",
    "    avg2 = bp.rolling(s2).sum() / tr.rolling(s2).sum()\n",
    "    avg3 = bp.rolling(s3).sum() / tr.rolling(s3).sum()\n",
    "    uo = 100 * (w1*avg1 + w2*avg2 + w3*avg3) / (w1+w2+w3)\n",
    "    return uo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdfac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical–Horizontal Filter\n",
    "def VHF(C, n=28):\n",
    "    num = C.rolling(n).max() - C.rolling(n).min()\n",
    "    den = C.diff().abs().rolling(n).sum()\n",
    "    return num / den\n",
    "\n",
    "# Williams Accumulation/Distribution\n",
    "def williamsAD(H, L, C):\n",
    "    clv = ((C - L) - (H - C)) / (H - L)\n",
    "    return clv  # as in TTR\n",
    "\n",
    "# Williams %R\n",
    "def WPR(H, L, C, n=14):\n",
    "    highest = H.rolling(n).max()\n",
    "    lowest = L.rolling(n).min()\n",
    "    return (highest - C) / (highest - lowest) * -100\n",
    "\n",
    "# ZigZag\n",
    "def ZigZag(H, L, C, pct=0.05):\n",
    "    zz = [np.nan] * len(C)\n",
    "    last_pivot = C.iloc[0]\n",
    "    last_dir = None\n",
    "\n",
    "    for i in range(1, len(C)):\n",
    "        change = (C.iloc[i] - last_pivot) / last_pivot\n",
    "        if last_dir is None:\n",
    "            if abs(change) > pct:\n",
    "                last_dir = np.sign(change)\n",
    "                last_pivot = C.iloc[i]\n",
    "                zz[i] = last_pivot\n",
    "        else:\n",
    "            if last_dir > 0 and C.iloc[i] > last_pivot:\n",
    "                last_pivot = C.iloc[i]\n",
    "                zz[i] = last_pivot\n",
    "            elif last_dir < 0 and C.iloc[i] < last_pivot:\n",
    "                last_pivot = C.iloc[i]\n",
    "                zz[i] = last_pivot\n",
    "            # reversal?\n",
    "            elif (last_dir > 0 and (C.iloc[i] - last_pivot) / last_pivot < -pct) or \\\n",
    "                 (last_dir < 0 and (C.iloc[i] - last_pivot) / last_pivot > pct):\n",
    "                last_dir *= -1\n",
    "                last_pivot = C.iloc[i]\n",
    "                zz[i] = last_pivot\n",
    "\n",
    "    return pd.Series(zz, index=C.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa7f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Triple Exponential Average oscillator (TRIX) ---\n",
    "def TRIX(C, n=9):\n",
    "    ema1 = EMA(C, n)\n",
    "    ema2 = EMA(ema1, n)\n",
    "    ema3 = EMA(ema2, n)\n",
    "    trix = ema3.pct_change() * 100\n",
    "    return trix\n",
    "\n",
    "# --- Traders Dynamic Index (TDI) ---\n",
    "def TDI(C, n_rsi=13, n_sig=2, n_bb=34, sd=1.618):\n",
    "    rsi = RSI(C, n_rsi)\n",
    "    signal = SMA(rsi, n_sig)\n",
    "    bb    = BBands(rsi, n_bb, sd)\n",
    "    return pd.DataFrame({\n",
    "        \"rsi\":    rsi,\n",
    "        \"signal\": signal,\n",
    "        \"bb_up\":  bb[\"bb_up\"],\n",
    "        \"bb_mid\": bb[\"bb_mid\"],\n",
    "        \"bb_dn\":  bb[\"bb_low\"]\n",
    "    })\n",
    "\n",
    "# --- Stochastic Momentum Index (SMI) ---\n",
    "def SMI(H, L, C, n=14, n_fast=3, n_slow=25, n_sig=9):\n",
    "    \n",
    "    # median price and half‐range\n",
    "    m = (H.rolling(n).max() + L.rolling(n).min()) / 2\n",
    "    d = (H.rolling(n).max() - L.rolling(n).min()) / 2\n",
    "\n",
    "    # double‐smoothed numerator and denominator\n",
    "    num = EMA(EMA(C - m, n_fast), n_slow)\n",
    "    den = EMA(EMA(d,       n_fast), n_slow)\n",
    "\n",
    "    smi    = 100 * (num / den)\n",
    "    signal = EMA(smi, n_sig)\n",
    "\n",
    "    return pd.DataFrame({\"smi\": smi, \"signal\": signal})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
