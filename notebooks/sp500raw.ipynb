{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import time\n",
    "from pytz import timezone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee7edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) —— Data Import & Preprocessing —— #\n",
    "\n",
    "DATA_DIR = \"../SPX\"\n",
    "OUTPUT_FEATURE_CSV = \"../csvfiles_python/features_360_raw.csv\"\n",
    "OUTPUT_ALLSET_CSV  = \"../csvfiles_python/allSet_360_raw.csv\"\n",
    "\n",
    "def load_data(path):\n",
    "    files = glob.glob(os.path.join(path, \"*.txt\"))\n",
    "    dfs = []\n",
    "    for f in sorted(files):\n",
    "        df = pd.read_csv(f, names=[\"DateTime\",\"Open\",\"High\",\"Low\",\"Close\"],\n",
    "                         sep=\",\", parse_dates=[\"DateTime\"])\n",
    "        dfs.append(df)\n",
    "    spx = pd.concat(dfs, ignore_index=True)\n",
    "    # localize to EST\n",
    "    spx[\"DateTime\"] = spx[\"DateTime\"].dt.tz_localize(timezone(\"US/Eastern\"))\n",
    "    spx.set_index(\"DateTime\", inplace=True)\n",
    "    # filter trading hours 9:30–16:00\n",
    "    return spx.between_time(\"09:30\",\"16:00\")\n",
    "\n",
    "spx = load_data(DATA_DIR)\n",
    "\n",
    "# Drop duplicates\n",
    "spx = spx[~spx.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bedfa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) —— Create daily labels —— #\n",
    "\n",
    "# group by calendar date\n",
    "spx[\"Date\"] = spx.index.date\n",
    "groups = spx.groupby(\"Date\")\n",
    "\n",
    "# last-minute close price per day\n",
    "lmP = groups[\"Close\"].last()\n",
    "\n",
    "# average price from start to (end − 30 mins)\n",
    "avgP = groups.apply(lambda df: df[\"Close\"].iloc[:-30].mean())\n",
    "\n",
    "# binary label: 1 if avgP < lmP else 0\n",
    "y = (avgP < lmP).astype(int)\n",
    "y.name = \"Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25aa98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) —— Technical‐Indicator Functions —— #\n",
    "\n",
    "# Basic EMAs & SMAs\n",
    "def SMA(x, n):\n",
    "    return x.rolling(n, min_periods=n).mean()\n",
    "\n",
    "def EMA(x, n):\n",
    "    return x.ewm(span=n, adjust=False).mean()\n",
    "\n",
    "def DEMA(x, n):\n",
    "    e = EMA(x, n)\n",
    "    return 2*e - EMA(e, n)\n",
    "\n",
    "# True Range & ATR\n",
    "def ATR(H, L, C, n=14):\n",
    "    prevC = C.shift(1)\n",
    "    tr = pd.concat([\n",
    "        H - L,\n",
    "        (H - prevC).abs(),\n",
    "        (L - prevC).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "    return EMA(tr, n)\n",
    "\n",
    "# Average Directional Index (ADX)\n",
    "def ADX(H, L, C, n=14):\n",
    "    up = H.diff()\n",
    "    down = -L.diff()\n",
    "    plusDM  = np.where((up>down)&(up>0), up, 0.0)\n",
    "    minusDM = np.where((down>up)&(down>0), down, 0.0)\n",
    "    tr = pd.concat([\n",
    "        H-L,\n",
    "        (H - C.shift(1)).abs(),\n",
    "        (L - C.shift(1)).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "    atr = EMA(tr, n)\n",
    "    plusDI  = 100 * EMA(pd.Series(plusDM, index=H.index), n) / atr\n",
    "    minusDI = 100 * EMA(pd.Series(minusDM, index=H.index), n) / atr\n",
    "    dx = 100 * ( (plusDI - minusDI).abs() / (plusDI + minusDI) )\n",
    "    return EMA(dx, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e23f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aroon\n",
    "def aroon(xH, xL, n=14):\n",
    "    def _aroon_up(series):\n",
    "        idx = series.argmax()\n",
    "        return ((n - (len(series)-1 - idx)) / n) * 100\n",
    "    def _aroon_dn(series):\n",
    "        idx = series.argmin()\n",
    "        return ((n - (len(series)-1 - idx)) / n) * 100\n",
    "\n",
    "    au = xH.rolling(n).apply(_aroon_up, raw=True)\n",
    "    ad = xL.rolling(n).apply(_aroon_dn, raw=True)\n",
    "    return pd.DataFrame({\"aroonUp\": au, \"aroonDn\": ad})\n",
    "\n",
    "# Bollinger Bands\n",
    "def BBands(x, n=20, k=2):\n",
    "    m = SMA(x, n)\n",
    "    sd = x.rolling(n).std()\n",
    "    return pd.DataFrame({\n",
    "        \"bb_up\":   m + k*sd,\n",
    "        \"bb_mid\":  m,\n",
    "        \"bb_low\":  m - k*sd\n",
    "    })\n",
    "\n",
    "# Commodity Channel Index\n",
    "def CCI(H, L, C, n=20):\n",
    "    TP = (H + L + C) / 3\n",
    "    M  = SMA(TP, n)\n",
    "    MD = TP.rolling(n).apply(lambda s: np.mean(np.abs(s - s.mean())), raw=True)\n",
    "    return (TP - M) / (0.015 * MD)\n",
    "\n",
    "# Chaikin Volatility\n",
    "def chaikin_volatility(H, L, n=10, ema_n=10):\n",
    "    hl = H - L\n",
    "    e1 = EMA(hl, ema_n)\n",
    "    e2 = e1.shift(n)\n",
    "    return (e1 - e2) / e2 * 100\n",
    "\n",
    "# Close Location Value\n",
    "def CLV(H, L, C):\n",
    "    return ((C - L) - (H - C)) / (H - L)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
